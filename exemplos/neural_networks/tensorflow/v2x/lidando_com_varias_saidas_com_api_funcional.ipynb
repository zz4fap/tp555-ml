{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2604f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57557cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a230bfb",
   "metadata": {},
   "source": [
    "### Lidando com modelos complexos.\n",
    "\n",
    "E se quisermos criar um modelo que envia um **subconjunto de atributos por um caminho curto**, **um subconjunto diferente de atributos (possivelmente sobreposto) por um caminho longo** ou profundo e que **possui uma saída adicional** (conforme mostrado na figura abaixo)?\n",
    "\n",
    "<img src=\"../../../../figures/rna_com_multiplas_saidas.png\" width=\"300px\">\n",
    "\n",
    "Nesse caso, uma solução é usar várias entradas (`inputs`) e múltiplas saídas (`outputs`).\n",
    "\n",
    "Uma arquitetura com várias entradas possibilita que a rede neural aprenda tanto **padrões complexos (usando o caminho longo)** quanto **padrões simples (através do caminho curto)**.\n",
    "\n",
    "Um caso onde múltiplas saídas são necessários ocorre quando queremos **localizar** e **classificar** um objeto em uma imagem. \n",
    "\n",
    "Esta é uma tarefa de regressão (encontrar as coordenadas do centro do objeto, bem como sua largura e altura) e uma tarefa de classificação.\n",
    "\n",
    "Neste exemplo, vamos usar novamente a base de dados habitacional da Califórnia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4365f295",
   "metadata": {},
   "source": [
    "### Carregando o conjunto de dados para regressão. \n",
    "\n",
    "+ Vamos usar o conjunto de dados habitacional da Califórnia e criar um regressor com uma rede neural.\n",
    "    + Esse conjunto possui 20640 exemplos e 8 atributos e 1 rótulo numéricos.\n",
    "    + O rótulo é o valor médio de casas no estado da Califórnia expresso em centenas de milhares de dólares.\n",
    "    + Para mais informações, acesse: https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset\n",
    "\n",
    "+ Usamos a função `fetch_california_housing()` do Scikit-Learn para carregar os dados.\n",
    "\n",
    "+ Depois de carregar os dados, dividimos em um conjunto de treinamento, um conjunto de validação e um conjunto de teste, e padronizamos todos os atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0fb23cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixa a base de dados.\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Divide o conjunto total de exemplos em conjuntos de treinamento e teste.\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "\n",
    "# Divide o conjunto de treinamento em conjuntos de treinamento (menor) e validação.\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "# Aplica padronização às matrizes de atributos.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c522ab",
   "metadata": {},
   "source": [
    "### Múltiplas entradas.\n",
    "\n",
    "Neste exemplo vamos enviar 5 atributos pelo caminho curto (atributos 0 a 4, totalizando 5 atributos) e 6 atributos pelo caminho longo (atributos 2 a 7, totalizando 6 atributos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "401ac17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando dois objetos do tipo \"Input\".\n",
    "input_A = keras.layers.Input(shape=[5], name=\"short_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653afb7b",
   "metadata": {},
   "source": [
    "### Camadas ocultas.\n",
    "\n",
    "+ Em seguida, criamos uma camada densa oculta (`Dense`) com 30 neurônios e usando a função de ativação `ReLU`. \n",
    "    + Assim que ela é criada, a **chamamos como uma função**, passando a entrada (`input_B`). \n",
    "        + É por isso que essa API é chamada de API Funcional. \n",
    "    + Observe que estamos apenas dizendo ao Keras como ele deve conectar as camadas, nenhum dado está sendo processado ainda.\n",
    "\n",
    "\n",
    "+ Na sequência, criamos uma segunda camada densa oculta e, novamente, a usamos como uma função. \n",
    "    + Observe, no entanto, que passamos a saída da primeira camada oculta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27f5c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = keras.layers.Dense(30, activation=\"relu\", name='hidden1')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\", name='hidden2')(hidden1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd58d78c",
   "metadata": {},
   "source": [
    "### Concatenando dados.\n",
    "\n",
    "Em seguida, usamos a função `keras.layers.concatenate()`, que cria uma camada do tipo `Concatenate` e imediatamente a chama com as entradas fornecidas, i.e., entrada A (`input_A`) e a saída da segunda camada oculta (ver a figura)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e75fbb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = keras.layers.concatenate([input_A, hidden2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c7cbea",
   "metadata": {},
   "source": [
    "### Múltiplas saídas.\n",
    "\n",
    "Na sequência, criamos as camadas de saída, **cada uma com um único neurônio e nenhuma função de ativação**, e as chamamos como uma função, passando o resultado da concatenação e a saída da segunda camada oculta, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4032847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camada de saída com um único neurônio e ativação linear.\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "\n",
    "# Camada de saída com um único neurônio e ativação linear.\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94676020",
   "metadata": {},
   "source": [
    "### Criando o modelo.\n",
    "\n",
    "Por fim, criamos um objeto do tipo `Model` do API Keras, especificando quais entradas e saídas usar.\n",
    "\n",
    "Como existem duas entradas e duas saída, precisamos passar uma lista com os respectivos objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d998f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Model(\n",
    "    inputs=[input_A, input_B],\n",
    "    outputs=[output, aux_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f775e0",
   "metadata": {},
   "source": [
    "### Compilando o modelo.\n",
    "\n",
    "+ Cada saída precisa de sua própria função de perda, portanto, quando compilarmos o modelo, devemos passar **uma lista de perdas**.\n",
    "    + Se passarmos uma única função de perda, o Keras assumirá que a mesma função deve ser usada para todas as saídas. \n",
    "\n",
    "\n",
    "+ Por padrão, o Keras calcula todas as perdas e as soma para obter a perda final usada para treinamento. \n",
    "\n",
    "\n",
    "+ No entanto, nesse exemplo, nos preocupamos muito mais com a saída principal do que com a saída auxiliar, então damos um peso muito maior à perda da saída principal através do parâmetro `loss_weights`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1d00a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c251066",
   "metadata": {},
   "source": [
    "### Separando os atributos e treinando o modelo.\n",
    "\n",
    "+ Antes de treinarmos o modelo com o método `fit` devemos criar as matrizes de atributos para treinamento, validação e teste.\n",
    "\n",
    "+ As matrizes de atributos A contém os atributos de 0 à 4 e as matrizes de atributos B, os atributos de 2 à 7.\n",
    "\n",
    "+ Passamos um par de matrizes (`X_train_A`, `X_train_B`), uma por entrada, para o método `fit`.\n",
    "\n",
    "+ Depois, precisamos fornecer os rótulos para cada saída. \n",
    "\n",
    "+ Neste exemplo, as duas saídas (principal e auxiliar) devem prever a mesma coisa, portanto, devem usar os mesmos rótulos. \n",
    "    + Então, passamos `[y_train, y_train]` para treinamento e `[y_valid, y_valid]` para validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85391a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 3s 5ms/step - loss: 0.8602 - main_output_loss: 0.7458 - aux_output_loss: 1.8899 - val_loss: 5.9702 - val_main_output_loss: 6.3391 - val_aux_output_loss: 2.6507\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5736 - main_output_loss: 0.5210 - aux_output_loss: 1.0469 - val_loss: 1.4693 - val_main_output_loss: 1.3954 - val_aux_output_loss: 2.1342\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5078 - main_output_loss: 0.4649 - aux_output_loss: 0.8936 - val_loss: 1.8651 - val_main_output_loss: 1.9608 - val_aux_output_loss: 1.0039\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4619 - main_output_loss: 0.4275 - aux_output_loss: 0.7711 - val_loss: 0.4492 - val_main_output_loss: 0.4084 - val_aux_output_loss: 0.8163\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4417 - main_output_loss: 0.4131 - aux_output_loss: 0.6997 - val_loss: 0.4053 - val_main_output_loss: 0.3770 - val_aux_output_loss: 0.6597\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4254 - main_output_loss: 0.4002 - aux_output_loss: 0.6521 - val_loss: 0.4129 - val_main_output_loss: 0.3882 - val_aux_output_loss: 0.6356\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4280 - main_output_loss: 0.4065 - aux_output_loss: 0.6216 - val_loss: 0.4002 - val_main_output_loss: 0.3799 - val_aux_output_loss: 0.5827\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4104 - main_output_loss: 0.3898 - aux_output_loss: 0.5954 - val_loss: 0.3866 - val_main_output_loss: 0.3667 - val_aux_output_loss: 0.5659\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4027 - main_output_loss: 0.3832 - aux_output_loss: 0.5776 - val_loss: 0.3858 - val_main_output_loss: 0.3656 - val_aux_output_loss: 0.5676\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3987 - main_output_loss: 0.3801 - aux_output_loss: 0.5663 - val_loss: 0.3727 - val_main_output_loss: 0.3524 - val_aux_output_loss: 0.5557\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4000 - main_output_loss: 0.3828 - aux_output_loss: 0.5543 - val_loss: 0.3656 - val_main_output_loss: 0.3454 - val_aux_output_loss: 0.5475\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3943 - main_output_loss: 0.3774 - aux_output_loss: 0.5460 - val_loss: 0.3643 - val_main_output_loss: 0.3424 - val_aux_output_loss: 0.5610\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3973 - main_output_loss: 0.3815 - aux_output_loss: 0.5394 - val_loss: 0.3563 - val_main_output_loss: 0.3362 - val_aux_output_loss: 0.5370\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3838 - main_output_loss: 0.3675 - aux_output_loss: 0.5311 - val_loss: 0.3555 - val_main_output_loss: 0.3359 - val_aux_output_loss: 0.5318\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3850 - main_output_loss: 0.3698 - aux_output_loss: 0.5213 - val_loss: 0.3612 - val_main_output_loss: 0.3445 - val_aux_output_loss: 0.5119\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3786 - main_output_loss: 0.3631 - aux_output_loss: 0.5176 - val_loss: 0.3531 - val_main_output_loss: 0.3351 - val_aux_output_loss: 0.5147\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3777 - main_output_loss: 0.3628 - aux_output_loss: 0.5114 - val_loss: 0.3593 - val_main_output_loss: 0.3366 - val_aux_output_loss: 0.5643\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3719 - main_output_loss: 0.3571 - aux_output_loss: 0.5043 - val_loss: 0.3479 - val_main_output_loss: 0.3311 - val_aux_output_loss: 0.4984\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3912 - main_output_loss: 0.3784 - aux_output_loss: 0.5065 - val_loss: 0.3482 - val_main_output_loss: 0.3303 - val_aux_output_loss: 0.5091\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3701 - main_output_loss: 0.3561 - aux_output_loss: 0.4964 - val_loss: 0.3424 - val_main_output_loss: 0.3247 - val_aux_output_loss: 0.5012\n"
     ]
    }
   ],
   "source": [
    "# Separando os atributos.\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B   = X_test[:, :5],  X_test[:, 2:]\n",
    "\n",
    "# Treinando o modelo.\n",
    "history = model.fit([X_train_A, X_train_B], \n",
    "                    [y_train, y_train], \n",
    "                    epochs=20, \n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid])\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6de9032",
   "metadata": {},
   "source": [
    "### Avaliando o modelo.\n",
    "\n",
    "Quando avaliamos o modelo com o conjunto de teste, o Keras retornará a perda total, bem como todas as perdas por saída individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03b08e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 1s 3ms/step - loss: 0.3608 - main_output_loss: 0.3481 - aux_output_loss: 0.4756\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822699a0",
   "metadata": {},
   "source": [
    "### Realizando predições com o modelo.\n",
    "\n",
    "Da mesma forma, o método `predict()` **retornará previsões para cada saída**.\n",
    "\n",
    "Testamos com os 3 primeiros exemplos do conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "880e3fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 240ms/step\n"
     ]
    }
   ],
   "source": [
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a245dda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 0.477 - Predicted main: 0.362 - Predicted aux: 0.744\n",
      "Actual: 0.458 - Predicted main: 1.532 - Predicted aux: 1.777\n",
      "Actual: 5.000 - Predicted main: 3.509 - Predicted aux: 3.089\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_pred_main)):\n",
    "    print('Actual: %1.3f - Predicted main: %1.3f - Predicted aux: %1.3f' % (y_test[i], y_pred_main[i], y_pred_aux[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42e794c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
