{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a2604f77",
      "metadata": {
        "id": "a2604f77"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "57557cd8",
      "metadata": {
        "id": "57557cd8"
      },
      "outputs": [],
      "source": [
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a230bfb",
      "metadata": {
        "id": "0a230bfb"
      },
      "source": [
        "### Lidando com modelos complexos.\n",
        "\n",
        "E se quisermos criar um modelo que envia um **subconjunto de atributos por um caminho curto**, **um subconjunto diferente de atributos (possivelmente sobreposto) por um caminho longo** ou profundo e que **possui uma saída adicional** (conforme mostrado na figura abaixo)?\n",
        "\n",
        "<img src=\"https://github.com/zz4fap/tp555-ml/blob/main/figures/rna_com_multiplas_saidas.png?raw=1\" width=\"300px\">\n",
        "\n",
        "Nesse caso, uma solução é usar várias entradas (`inputs`) e múltiplas saídas (`outputs`).\n",
        "\n",
        "Uma arquitetura com várias entradas possibilita que a rede neural aprenda tanto **padrões complexos (usando o caminho longo)** quanto **padrões simples (através do caminho curto)**.\n",
        "\n",
        "Um caso onde múltiplas saídas são necessárias ocorre quando queremos **localizar** e **classificar** um objeto em uma imagem.\n",
        "\n",
        "Esta é uma tarefa de regressão (encontrar as coordenadas do centro do objeto, bem como sua largura e altura) e uma tarefa de classificação.\n",
        "\n",
        "Neste exemplo, vamos usar novamente a base de dados habitacional da Califórnia."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4365f295",
      "metadata": {
        "id": "4365f295"
      },
      "source": [
        "### Carregando o conjunto de dados para regressão.\n",
        "\n",
        "+ Vamos usar o conjunto de dados habitacional da Califórnia e criar um regressor com uma rede neural.\n",
        "    + Esse conjunto possui 20640 exemplos e 8 atributos e 1 rótulo numéricos.\n",
        "    + O rótulo é o valor médio de casas no estado da Califórnia expresso em centenas de milhares de dólares.\n",
        "    + Para mais informações, acesse: https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset\n",
        "\n",
        "+ Usamos a função `fetch_california_housing()` do Scikit-Learn para carregar os dados.\n",
        "\n",
        "+ Depois de carregar os dados, dividimos em um conjunto de treinamento, um conjunto de validação e um conjunto de teste, e padronizamos todos os atributos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c0fb23cd",
      "metadata": {
        "id": "c0fb23cd"
      },
      "outputs": [],
      "source": [
        "# Baixa a base de dados.\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "# Divide o conjunto total de exemplos em conjuntos de treinamento e teste.\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
        "\n",
        "# Divide o conjunto de treinamento em conjuntos de treinamento (menor) e validação.\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "# Aplica padronização às matrizes de atributos.\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29c522ab",
      "metadata": {
        "id": "29c522ab"
      },
      "source": [
        "### Múltiplas entradas.\n",
        "\n",
        "Neste exemplo vamos enviar 5 atributos pelo caminho curto (atributos 0 a 4, totalizando 5 atributos) e 6 atributos pelo caminho longo (atributos 2 a 7, totalizando 6 atributos).\n",
        "\n",
        "\n",
        "Quando usamos a API funcional, devemos definiar camadas de entrada através da classe `Input`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "401ac17c",
      "metadata": {
        "id": "401ac17c"
      },
      "outputs": [],
      "source": [
        "# Instanciando dois objetos do tipo \"Input\".\n",
        "input_A = keras.Input(shape=[5], name=\"short_input\")\n",
        "input_B = keras.Input(shape=[6], name=\"deep_input\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "653afb7b",
      "metadata": {
        "id": "653afb7b"
      },
      "source": [
        "### Camadas ocultas.\n",
        "\n",
        "+ Em seguida, criamos uma camada densa oculta (`Dense`) com 30 neurônios e usando a função de ativação `ReLU`.\n",
        "    + Assim que ela é criada, a **chamamos como uma função**, passando a entrada (`input_B`).\n",
        "        + É por isso que essa API é chamada de API funcional.\n",
        "    + **OBS.**: Observe que estamos apenas dizendo ao Keras como ele deve conectar as camadas, nenhum dado está sendo processado ainda.\n",
        "\n",
        "\n",
        "+ Na sequência, criamos uma segunda camada densa oculta e, novamente, a usamos como uma função.\n",
        "    + Observe, no entanto, que passamos a saída da primeira camada oculta como entrada desta camada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "27f5c7e4",
      "metadata": {
        "id": "27f5c7e4"
      },
      "outputs": [],
      "source": [
        "hidden1 = layers.Dense(30, activation=\"relu\", name='hidden1')(input_B)\n",
        "hidden2 = layers.Dense(30, activation=\"relu\", name='hidden2')(hidden1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd58d78c",
      "metadata": {
        "id": "dd58d78c"
      },
      "source": [
        "### Concatenando dados.\n",
        "\n",
        "Em seguida, usamos a função `keras.layers.concatenate()`, que cria uma camada do tipo `Concatenate` e imediatamente a chama com as entradas fornecidas, i.e., entrada A (`input_A`) e a saída da segunda camada oculta (ver a figura)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e75fbb92",
      "metadata": {
        "id": "e75fbb92"
      },
      "outputs": [],
      "source": [
        "concat = layers.concatenate([input_A, hidden2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9c7cbea",
      "metadata": {
        "id": "d9c7cbea"
      },
      "source": [
        "### Múltiplas saídas.\n",
        "\n",
        "Na sequência, criamos as camadas de saída, **cada uma com um único neurônio e nenhuma função de ativação**, e as chamamos como uma função, passando o resultado da concatenação e a saída da segunda camada oculta, respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4032847e",
      "metadata": {
        "id": "4032847e"
      },
      "outputs": [],
      "source": [
        "# Camada de saída com um único neurônio e ativação linear.\n",
        "output = layers.Dense(1, name=\"main_output\")(concat)\n",
        "\n",
        "# Camada de saída com um único neurônio e ativação linear.\n",
        "aux_output = layers.Dense(1, name=\"aux_output\")(hidden2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94676020",
      "metadata": {
        "id": "94676020"
      },
      "source": [
        "### Criando o modelo.\n",
        "\n",
        "Por fim, criamos um objeto do tipo `Model` do API Keras, especificando quais entradas e saídas usar.\n",
        "\n",
        "Como existem duas entradas e duas saída, precisamos passar uma **lista** com os respectivos objetos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2d998f3b",
      "metadata": {
        "id": "2d998f3b"
      },
      "outputs": [],
      "source": [
        "model = keras.Model(\n",
        "    inputs=[input_A, input_B],\n",
        "    outputs=[output, aux_output]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2f775e0",
      "metadata": {
        "id": "d2f775e0"
      },
      "source": [
        "### Compilando o modelo.\n",
        "\n",
        "+ Cada saída precisa de sua própria função de perda, portanto, quando compilarmos o modelo, devemos passar **uma lista de perdas**.\n",
        "    + Se passarmos uma única função de perda, o Keras assumirá que a mesma função deve ser usada para todas as saídas.\n",
        "\n",
        "\n",
        "+ **Por padrão, o Keras calcula todas as perdas e as soma para obter a perda final usada para o treinamento.**\n",
        "\n",
        "\n",
        "+ No entanto, nesse exemplo, nos preocupamos muito mais com a saída principal do que com a saída auxiliar, então damos um peso muito maior à perda da saída principal através do parâmetro `loss_weights`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e1d00a83",
      "metadata": {
        "id": "e1d00a83"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='sgd', loss_weights=[0.9, 0.1], loss=['mse', 'mse'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c251066",
      "metadata": {
        "id": "2c251066"
      },
      "source": [
        "### Separando os atributos e treinando o modelo.\n",
        "\n",
        "+ Antes de treinarmos o modelo com o método `fit` devemos criar as matrizes de atributos para treinamento, validação e teste.\n",
        "\n",
        "+ As matrizes de atributos A contêm os atributos de 0 à 4 e as matrizes de atributos B, os atributos de 2 à 7.\n",
        "\n",
        "+ Passamos um par de matrizes (`X_train_A`, `X_train_B`), uma por entrada, para o método `fit`.\n",
        "\n",
        "+ Depois, precisamos fornecer os rótulos para cada saída.\n",
        "\n",
        "+ Neste exemplo, as duas saídas (principal e auxiliar) devem prever a mesma coisa, portanto, devem usar os mesmos rótulos.\n",
        "    + Então, passamos `[y_train, y_train]` para treinamento e `[y_valid, y_valid]` para validação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "85391a26",
      "metadata": {
        "id": "85391a26",
        "outputId": "09fd2798-2e21-496c-f995-637979a2da97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - aux_output_loss: 0.3024 - loss: 1.3763 - main_output_loss: 1.0739 - val_aux_output_loss: 0.7106 - val_loss: 3.4701 - val_main_output_loss: 2.7579\n",
            "Epoch 2/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - aux_output_loss: 0.1105 - loss: 0.5457 - main_output_loss: 0.4352 - val_aux_output_loss: 0.0873 - val_loss: 0.5034 - val_main_output_loss: 0.4159\n",
            "Epoch 3/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_output_loss: 0.0850 - loss: 0.4986 - main_output_loss: 0.4136 - val_aux_output_loss: 0.1134 - val_loss: 7.8957 - val_main_output_loss: 7.7784\n",
            "Epoch 4/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_output_loss: 0.0757 - loss: 0.4980 - main_output_loss: 0.4223 - val_aux_output_loss: 0.1884 - val_loss: 1.7974 - val_main_output_loss: 1.6082\n",
            "Epoch 5/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - aux_output_loss: 0.0691 - loss: 0.4656 - main_output_loss: 0.3965 - val_aux_output_loss: 0.0662 - val_loss: 0.4228 - val_main_output_loss: 0.3565\n",
            "Epoch 6/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - aux_output_loss: 0.0651 - loss: 0.4510 - main_output_loss: 0.3858 - val_aux_output_loss: 0.0614 - val_loss: 0.4347 - val_main_output_loss: 0.3732\n",
            "Epoch 7/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - aux_output_loss: 0.0626 - loss: 0.4436 - main_output_loss: 0.3810 - val_aux_output_loss: 0.0599 - val_loss: 0.4122 - val_main_output_loss: 0.3523\n",
            "Epoch 8/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - aux_output_loss: 0.0609 - loss: 0.4388 - main_output_loss: 0.3779 - val_aux_output_loss: 0.0564 - val_loss: 0.4182 - val_main_output_loss: 0.3617\n",
            "Epoch 9/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - aux_output_loss: 0.0597 - loss: 0.4341 - main_output_loss: 0.3744 - val_aux_output_loss: 0.0567 - val_loss: 0.3949 - val_main_output_loss: 0.3381\n",
            "Epoch 10/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - aux_output_loss: 0.0587 - loss: 0.4302 - main_output_loss: 0.3715 - val_aux_output_loss: 0.0537 - val_loss: 0.4236 - val_main_output_loss: 0.3697\n",
            "Epoch 11/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_output_loss: 0.0577 - loss: 0.4250 - main_output_loss: 0.3673 - val_aux_output_loss: 0.0563 - val_loss: 0.3818 - val_main_output_loss: 0.3254\n",
            "Epoch 12/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_output_loss: 0.0569 - loss: 0.4208 - main_output_loss: 0.3639 - val_aux_output_loss: 0.0524 - val_loss: 0.3969 - val_main_output_loss: 0.3444\n",
            "Epoch 13/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_output_loss: 0.0559 - loss: 0.4162 - main_output_loss: 0.3602 - val_aux_output_loss: 0.0528 - val_loss: 0.3749 - val_main_output_loss: 0.3221\n",
            "Epoch 14/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_output_loss: 0.0551 - loss: 0.4107 - main_output_loss: 0.3556 - val_aux_output_loss: 0.0556 - val_loss: 0.4706 - val_main_output_loss: 0.4148\n",
            "Epoch 15/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_output_loss: 0.0542 - loss: 0.4045 - main_output_loss: 0.3503 - val_aux_output_loss: 0.0547 - val_loss: 0.3892 - val_main_output_loss: 0.3344\n",
            "Epoch 16/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_output_loss: 0.0535 - loss: 0.4012 - main_output_loss: 0.3477 - val_aux_output_loss: 0.0538 - val_loss: 0.4456 - val_main_output_loss: 0.3917\n",
            "Epoch 17/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_output_loss: 0.0527 - loss: 0.3972 - main_output_loss: 0.3445 - val_aux_output_loss: 0.0496 - val_loss: 0.3619 - val_main_output_loss: 0.3122\n",
            "Epoch 18/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_output_loss: 0.0519 - loss: 0.3930 - main_output_loss: 0.3411 - val_aux_output_loss: 0.0484 - val_loss: 0.3894 - val_main_output_loss: 0.3409\n",
            "Epoch 19/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_output_loss: 0.0511 - loss: 0.3892 - main_output_loss: 0.3381 - val_aux_output_loss: 0.0486 - val_loss: 0.3627 - val_main_output_loss: 0.3141\n",
            "Epoch 20/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_output_loss: 0.0505 - loss: 0.3861 - main_output_loss: 0.3356 - val_aux_output_loss: 0.0501 - val_loss: 0.3959 - val_main_output_loss: 0.3457\n"
          ]
        }
      ],
      "source": [
        "# Separando os atributos.\n",
        "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
        "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
        "X_test_A, X_test_B   = X_test[:, :5],  X_test[:, 2:]\n",
        "\n",
        "# Treinando o modelo.\n",
        "history = model.fit([X_train_A, X_train_B],\n",
        "                    [y_train, y_train],\n",
        "                    epochs=20,\n",
        "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid])\n",
        "                   )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6de9032",
      "metadata": {
        "id": "c6de9032"
      },
      "source": [
        "### Avaliando o modelo.\n",
        "\n",
        "Quando avaliamos o modelo com o conjunto de teste, o Keras retornará a perda total, bem como todas as perdas por saída individual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "03b08e0f",
      "metadata": {
        "id": "03b08e0f",
        "outputId": "9e780d0a-b11b-4a76-e018-80d7ab716b0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - aux_output_loss: 0.0473 - loss: 0.3741 - main_output_loss: 0.3268\n"
          ]
        }
      ],
      "source": [
        "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "822699a0",
      "metadata": {
        "id": "822699a0"
      },
      "source": [
        "### Realizando predições com o modelo.\n",
        "\n",
        "Da mesma forma, o método `predict()` **retornará previsões para cada saída**.\n",
        "\n",
        "Testamos com os 3 primeiros exemplos do conjunto de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "880e3fb9",
      "metadata": {
        "id": "880e3fb9",
        "outputId": "f7452b87-dc5b-4a3a-8c5a-c3707c157821",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n"
          ]
        }
      ],
      "source": [
        "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
        "\n",
        "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a245dda4",
      "metadata": {
        "id": "a245dda4",
        "outputId": "a6f11f01-8ef6-43cb-9702-fa2587169e90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual: 0.477 - Predicted main: 0.641 - Predicted aux: 0.789\n",
            "Actual: 0.458 - Predicted main: 1.557 - Predicted aux: 1.726\n",
            "Actual: 5.000 - Predicted main: 3.679 - Predicted aux: 3.382\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(y_pred_main)):\n",
        "    print('Actual: %1.3f - Predicted main: %1.3f - Predicted aux: %1.3f' % (y_test[i], y_pred_main[i,0], y_pred_aux[i,0]))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}