{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd1b41e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f8f7d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c342a3",
   "metadata": {},
   "source": [
    "### Carregando o conjunto de dados para regressão. \n",
    "\n",
    "+ Vamos usar o conjunto de dados habitacional da Califórnia e criar um regressor com uma rede neural.\n",
    "\n",
    "+ Depois de carregar os dados, dividimos em um conjunto de treinamento, um conjunto de validação e um conjunto de teste, e padronizamos todos os atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5847c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixa a base de dados.\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Divide o conjunto total de exemplos em conjuntos de treinamento e teste.\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "\n",
    "# Divide o conjunto de treinamento em conjuntos de treinamento (menor) e validação.\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "# Aplica padronização às matrizes de atributos.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a8530",
   "metadata": {},
   "source": [
    "### Diretório de logs\n",
    "\n",
    "Em geral, apontamos o servidor do TensorBoard para um **diretório de log raiz** e configuramos o código para que ele grave em um **subdiretório diferente toda vez que for executado**. \n",
    "\n",
    "Dessa forma, a mesma instância do servidor do TensorBoard permitirá que você visualize e compare dados de várias execuções do seu código, sem misturá-los.\n",
    "\n",
    "Portanto, começamos definindo o diretório de log raiz que usaremos para armazenar os logs do TensorBoard, além de uma função que gerará um caminho do subdiretório com base na data e hora atuais, para que ele seja diferente a cada execução. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c7462c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório raiz: .\\my_logs\n",
      "Subdiretório raiz: .\\my_logs\\run_2023_06_14-22_58_51\n"
     ]
    }
   ],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "print('Diretório raiz:', root_logdir)\n",
    "\n",
    "def get_run_logdir(root_logdir):\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir(root_logdir)\n",
    "print('Subdiretório raiz:', run_logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee038d05",
   "metadata": {},
   "source": [
    "### Criando e compilando o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "494ec9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(30, activation=\"relu\", input_shape=[8], name='hidden1'),\n",
    "        keras.layers.Dense(30, activation=\"relu\", name='hidden2'),\n",
    "        keras.layers.Dense(1, name='output')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807ede88",
   "metadata": {},
   "source": [
    "### Tensorboard callback\n",
    "\n",
    "O Keras fornece uma callback chamada **TensorBoard**, a qual passamos o caminho do **subdiretório** através do parâmetro `log_dir`.\n",
    "\n",
    "\n",
    "O parâmetro `histogram_freq` configura a frequência (em épocas) em que os histogramas dos pesos das camadas do modelo são calculados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1d80f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=run_logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4133ac5c",
   "metadata": {},
   "source": [
    "### Treinando o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61764861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 3.6085 - val_loss: 7.5774\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.6045 - val_loss: 9.5229\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.0247 - val_loss: 9.8846\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.6750 - val_loss: 8.9279\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.4462 - val_loss: 7.6330\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.2843 - val_loss: 6.6214\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1650 - val_loss: 5.5855\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0741 - val_loss: 4.5773\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0023 - val_loss: 3.7520\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9443 - val_loss: 3.0705\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8976 - val_loss: 2.5062\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8599 - val_loss: 2.0736\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8287 - val_loss: 1.7252\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8028 - val_loss: 1.4537\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7811 - val_loss: 1.2428\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7625 - val_loss: 1.0814\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7465 - val_loss: 0.9568\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7324 - val_loss: 0.8617\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7200 - val_loss: 0.7905\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7088 - val_loss: 0.7409\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6986 - val_loss: 0.7056\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6891 - val_loss: 0.6785\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6802 - val_loss: 0.6581\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6719 - val_loss: 0.6429\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6640 - val_loss: 0.6314\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6564 - val_loss: 0.6232\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6493 - val_loss: 0.6172\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6424 - val_loss: 0.6131\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6358 - val_loss: 0.6101\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6295 - val_loss: 0.6092\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04bc2ed",
   "metadata": {},
   "source": [
    "### Inicializando o servidor do Tensorboard\n",
    "\n",
    "Em seguida, executamos o seguinte comando na raiz do projeto (ou de qualquer outro lugar, desde que apontemos para o diretório de log apropriado).\n",
    "\n",
    "Para iniciar o servidor TensorBoard, uma opção é abrir um terminal. Em seguida, acessamos o diretório deste notebook e digitamos:\n",
    "\n",
    "`$ tensorboard --logdir=./my_logs --port=6006`\n",
    "\n",
    "Na sequência, abrimos o navegador web e o apontamos para `localhost:6006` e usamos o TensorBoard.\n",
    "\n",
    "Como alternativa, podemos carregar a extensão Jupyter do TensorBoard e executá-lo como mostrado abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b90b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0696aabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5d920aab52095893\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5d920aab52095893\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1344ce37",
   "metadata": {},
   "source": [
    "#### Observações.\n",
    "\n",
    "+ Além do erro real, o tensorboard mostra uma versão suavizada do erro (**smoothed**), onde se aplica uma **média móvel exponencialmente descrescente** aos valores do erro.\n",
    "    + A suavização ajuda a analisar a tendência do erro quando as atualizações são muito ruidosas.\n",
    "\n",
    "\n",
    "+ O **histograma** dos pesos das camadas mostra no eixo x o intervalo de valores dos pesos, no eixo y, a ocorrência normalizada dos valores e no eixo z, e época."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca36b098",
   "metadata": {},
   "source": [
    "### Executando o modelo com valor maior para o passo de aprendizagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff4286da",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b14ca78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subdiretório raiz: .\\my_logs\\run_2023_06_14-22_59_20\n"
     ]
    }
   ],
   "source": [
    "run_logdir2 = get_run_logdir(root_logdir)\n",
    "print('Subdiretório raiz:', run_logdir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12899cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(30, activation=\"relu\", input_shape=[8], name='hidden1'),\n",
    "        keras.layers.Dense(30, activation=\"relu\", name='hidden2'),\n",
    "        keras.layers.Dense(1, name='output')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f54705d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.9040 - val_loss: 0.9000\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8061 - val_loss: 0.7393\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7144 - val_loss: 0.6543\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6683 - val_loss: 0.6760\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6326 - val_loss: 0.6377\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6010 - val_loss: 0.6279\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5743 - val_loss: 0.5825\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5500 - val_loss: 0.5698\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5282 - val_loss: 0.5600\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5091 - val_loss: 0.5496\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4927 - val_loss: 0.5555\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4786 - val_loss: 0.5469\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4669 - val_loss: 0.5471\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4570 - val_loss: 0.5391\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4485 - val_loss: 0.5422\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4413 - val_loss: 0.5218\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4353 - val_loss: 0.5644\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4300 - val_loss: 0.5801\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4246 - val_loss: 0.5271\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4208 - val_loss: 0.6227\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4167 - val_loss: 0.5859\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4131 - val_loss: 0.6084\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4097 - val_loss: 0.4840\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4064 - val_loss: 0.5212\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4032 - val_loss: 0.5909\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4008 - val_loss: 0.5802\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3984 - val_loss: 0.4770\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3958 - val_loss: 0.5482\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3938 - val_loss: 0.5009\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3913 - val_loss: 0.5617\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=run_logdir2, histogram_freq=1)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837e52ab",
   "metadata": {},
   "source": [
    "+ Observe como o TensorBoard agora vê duas execuções e podemos comparar as curvas de aprendizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac79cf3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 17048), started 0:00:21 ago. (Use '!kill 17048' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-81e1fd5a1e8d836b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-81e1fd5a1e8d836b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70a947b",
   "metadata": {},
   "source": [
    "### Observação\n",
    "\n",
    "+ Observem que a perda de treinamento caiu bastante durante as duas execuções, mas a segunda foi muito mais rápida. \n",
    "\n",
    "\n",
    "+ Isso se deve ao fato de termos usado uma taxa de aprendizado maior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409d93a5",
   "metadata": {},
   "source": [
    "### Referências\n",
    "\n",
    "[1] https://towardsdatascience.com/a-quickstart-guide-to-tensorboard-fb1ade69bbcf\n",
    "\n",
    "[2] https://neptune.ai/blog/tensorboard-tutorial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
