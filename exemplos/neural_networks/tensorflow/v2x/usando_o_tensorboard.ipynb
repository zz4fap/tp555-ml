{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd1b41e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f8f7d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c342a3",
   "metadata": {},
   "source": [
    "### Carregando o conjunto de dados para regressão. \n",
    "\n",
    "+ Vamos usar o conjunto de dados habitacional da Califórnia e criar um regressor com uma rede neural.\n",
    "\n",
    "+ Depois de carregar os dados, dividimos em um conjunto de treinamento, um conjunto de validação e um conjunto de teste, e padronizamos todos os atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5847c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixa a base de dados.\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Divide o conjunto total de exemplos em conjuntos de treinamento e teste.\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "\n",
    "# Divide o conjunto de treinamento em conjuntos de treinamento (menor) e validação.\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "# Aplica padronização às matrizes de atributos.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a8530",
   "metadata": {},
   "source": [
    "### Diretório de logs\n",
    "\n",
    "Em geral, apontamos o servidor TensorBoard para um diretório de log raiz e configuramos o código para que ele grave em um subdiretório diferente toda vez que for executado. \n",
    "\n",
    "Dessa forma, a mesma instância do servidor do TensorBoard permitirá que você visualize e compare dados de várias execuções do seu código, sem misturá-los.\n",
    "\n",
    "Portanto, começamos definindo o diretório de log raiz que usaremos para armazenar os logs do TensorBoard, além de uma função que gerará um caminho do subdiretório com base na data e hora atuais, para que ele seja diferente a cada execução. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c7462c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório raiz: .\\my_logs\n",
      "Subdiretório raiz: .\\my_logs\\run_2022_11_15-09_09_13\n"
     ]
    }
   ],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "print('Diretório raiz:', root_logdir)\n",
    "\n",
    "def get_run_logdir(root_logdir):\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir(root_logdir)\n",
    "print('Subdiretório raiz:', run_logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee038d05",
   "metadata": {},
   "source": [
    "### Criando e compilando o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "494ec9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "        keras.layers.Dense(30, activation=\"relu\"),\n",
    "        keras.layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807ede88",
   "metadata": {},
   "source": [
    "### Tensorboard callback\n",
    "\n",
    "O Keras fornece uma callback chamada **TensorBoard**, a qual passamos o caminho do subdiretório através do parâmetro `log_dir`.\n",
    "\n",
    "O parâmetro `histogram_freq` configura a frequência (em épocas) em que os histogramas dos pesos das camadas do modelo são calculados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1d80f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=run_logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4133ac5c",
   "metadata": {},
   "source": [
    "### Treinando o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61764861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 3s 5ms/step - loss: 1.8866 - val_loss: 0.7126\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6577 - val_loss: 0.6880\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5934 - val_loss: 0.5803\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5557 - val_loss: 0.5166\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5272 - val_loss: 0.4895\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5033 - val_loss: 0.4951\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4854 - val_loss: 0.4861\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4709 - val_loss: 0.4554\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4578 - val_loss: 0.4413\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4474 - val_loss: 0.4379\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4393 - val_loss: 0.4396\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4318 - val_loss: 0.4507\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4261 - val_loss: 0.3997\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4202 - val_loss: 0.3956\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4155 - val_loss: 0.3916\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4112 - val_loss: 0.3937\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4077 - val_loss: 0.3809\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4040 - val_loss: 0.3793\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4004 - val_loss: 0.3850\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3980 - val_loss: 0.3809\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3949 - val_loss: 0.3701\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3924 - val_loss: 0.3781\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3898 - val_loss: 0.3650\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3874 - val_loss: 0.3655\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3851 - val_loss: 0.3611\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3829 - val_loss: 0.3626\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3809 - val_loss: 0.3564\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3788 - val_loss: 0.3579\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3769 - val_loss: 0.3561\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3750 - val_loss: 0.3548\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04bc2ed",
   "metadata": {},
   "source": [
    "### Inicializando o servidor do Tensorboard\n",
    "\n",
    "Em seguida, executamos o seguinte comando na raiz do projeto (ou de qualquer outro lugar, desde que apontemos para o diretório de log apropriado).\n",
    "\n",
    "Para iniciar o servidor TensorBoard, uma opção é abrir um terminal. Em seguida, acessamos o diretório deste notebook e digitamos:\n",
    "\n",
    "`$ tensorboard --logdir=./my_logs --port=6006`\n",
    "\n",
    "Na sequência, abrimos o navegador web e o apontamos para `localhost:6006` e usamos o TensorBoard.\n",
    "\n",
    "Como alternativa, podemos carregar a extensão Jupyter do TensorBoard e executá-la como mostrado abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b90b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0696aabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3196), started 0:36:24 ago. (Use '!kill 3196' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4a29ba7288fb324a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4a29ba7288fb324a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1344ce37",
   "metadata": {},
   "source": [
    "#### Observações.\n",
    "\n",
    "+ Além do erro real, o tensorboard mostra uma versão suavizada do erro (**smoothed**), onde se aplica uma média movente exponencialmente descrescente aos valores do erro.\n",
    "\n",
    "\n",
    "+ A suavização ajuda a analisar a tendência do erro quando as atualizações são muito ruidosas.\n",
    "\n",
    "\n",
    "+ O **histograma** dos pesos das camadas mostra no eixo x o intervalo de valores dos pesos, no eixo y, a ocorrência normalizada dos valores e no eixo z, e época."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca36b098",
   "metadata": {},
   "source": [
    "### Executando o modelo com valor maior para o passo de aprendizagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff4286da",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b14ca78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subdiretório raiz: .\\my_logs\\run_2022_11_15-09_09_56\n"
     ]
    }
   ],
   "source": [
    "run_logdir2 = get_run_logdir(root_logdir)\n",
    "print('Subdiretório raiz:', run_logdir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12899cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "        keras.layers.Dense(30, activation=\"relu\"),\n",
    "        keras.layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f54705d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 3s 4ms/step - loss: 0.5530 - val_loss: 302.8540\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 89.0721 - val_loss: 0.9483\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 1.0742 - val_loss: 0.9875\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 1.0411 - val_loss: 1.4473\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 1.0134 - val_loss: 0.9880\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 1.0047 - val_loss: 0.9960\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.9764 - val_loss: 0.8428\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.9586 - val_loss: 0.9234\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.9941 - val_loss: 0.8979\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.9612 - val_loss: 0.8838\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.8927 - val_loss: 0.7730\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.8924 - val_loss: 0.8883\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.8788 - val_loss: 0.7827\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.8731 - val_loss: 0.8474\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.8686 - val_loss: 0.8511\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.8736 - val_loss: 0.8272\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.8455 - val_loss: 0.8747\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8611 - val_loss: 0.8047\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8131 - val_loss: 0.7315\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.8271 - val_loss: 0.8099\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.8501 - val_loss: 0.8112\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.8260 - val_loss: 0.7588\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.9498 - val_loss: 1.1519\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.2727 - val_loss: 1.3799\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 1.3522 - val_loss: 1.3196\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 1.3444 - val_loss: 1.3197\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.3430 - val_loss: 1.3158\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 1.3426 - val_loss: 1.3223\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 1.3431 - val_loss: 1.3267\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3423 - val_loss: 1.3173\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=run_logdir2, histogram_freq=1)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837e52ab",
   "metadata": {},
   "source": [
    "Observe como o TensorBoard agora vê duas execuções e podemos comparar as curvas de aprendizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac79cf3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3196), started 0:37:10 ago. (Use '!kill 3196' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6fb2d59c3db63f70\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6fb2d59c3db63f70\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70a947b",
   "metadata": {},
   "source": [
    "### Observação\n",
    "\n",
    "+ Observem que a perda de treinamento caiu bem durante as duas execuções, mas a segunda foi muito mais rápida. \n",
    "\n",
    "\n",
    "+ Isso se deve ao fato de termos usado uma taxa de aprendizado maior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409d93a5",
   "metadata": {},
   "source": [
    "### Referências\n",
    "\n",
    "[1] https://towardsdatascience.com/a-quickstart-guide-to-tensorboard-fb1ade69bbcf\n",
    "\n",
    "[2] https://neptune.ai/blog/tensorboard-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd5fe95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b872f870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
