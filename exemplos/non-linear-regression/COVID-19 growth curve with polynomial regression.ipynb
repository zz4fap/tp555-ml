{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-24b039e7be7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objects\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import tqdm\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "INPUT_PREFIX = './data/time_series_covid_19'\n",
    "\n",
    "df_confirmed = pd.read_csv(\n",
    "    INPUT_PREFIX + '_confirmed.csv').drop(['Province/State', 'Lat', 'Long'], axis=1).groupby(by='Country/Region').sum().reset_index()\n",
    "df_recovered = pd.read_csv(INPUT_PREFIX + '_recovered.csv').drop(['Province/State', 'Lat', 'Long'], axis=1).groupby(by='Country/Region').sum().reset_index()\n",
    "df_deaths = pd.read_csv(INPUT_PREFIX + '_deaths.csv').drop(['Province/State', 'Lat', 'Long'], axis=1).groupby(by='Country/Region').sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = list(df_confirmed.columns)[1::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_merged = pd.DataFrame(columns=['country', 'date', 'confirmed', 'recovered', 'deaths'])\n",
    "\n",
    "for r, row in tqdm.tqdm(df_confirmed.iterrows(), total=df_confirmed.shape[0]):\n",
    "    for date in dates:\n",
    "        df_merged = df_merged.append(\n",
    "            {\n",
    "                'country': row['Country/Region'],\n",
    "                'date_raw': date,\n",
    "                'confirmed': df_confirmed[df_confirmed['Country/Region']==row['Country/Region']][date].values[0],\n",
    "                'recovered': df_recovered[df_recovered['Country/Region']==row['Country/Region']][date].values[0],\n",
    "                'deaths': df_deaths[df_deaths['Country/Region']==row['Country/Region']][date].values[0]\n",
    "            },\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "df_merged['active'] = df_merged['confirmed'] - df_merged['recovered'] - df_merged['deaths'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['date'] = df_merged['date_raw'].map(lambda d: datetime.strptime(d, '%m/%d/%y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged[df_merged['country'].isin(['Italy', 'China', 'Spain', 'Portugal', 'France', 'US', 'Japan', 'Brazil'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_filtered=df_merged[df_merged['country']=='Brazil']\n",
    "df_merged_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_merged_filtered[df_merged_filtered['confirmed']>=1]\n",
    "\n",
    "days_from_k_cases = []\n",
    "\n",
    "for _, row in df_filtered.iterrows():\n",
    "    aux = (row['date'] - df_filtered[df_filtered['country'] == row['country']]['date'].min()).days + 1\n",
    "    days_from_k_cases.append(aux)\n",
    "    \n",
    "df_filtered['days_from_k_case'] = days_from_k_cases\n",
    "\n",
    "initial_day = df_filtered[df_filtered['country'] == row['country']]['date'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping country for regression modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw, y_raw = [], []\n",
    "\n",
    "for country, df_country in df_filtered.groupby(by='country'):\n",
    "    X_raw += list(df_country['days_from_k_case'].values)\n",
    "    y_raw += list(df_country['active'].values)\n",
    "    \n",
    "X = np.array(X_raw).reshape(-1, 1)\n",
    "y = np.array(y_raw)\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "writer = csv.writer(open(\"covid19.csv\", 'w'), delimiter=',')\n",
    "for row in y:\n",
    "    writer.writerow((X[i][0], y[i]))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the whole set into random training and validation set.\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "include_bias = False\n",
    "error_train = []\n",
    "error_val = []\n",
    "mean_vec = []\n",
    "std_vec = []\n",
    "for d in range(1, 13):\n",
    "    # Instantiate a polynomial.\n",
    "    poly_features = PolynomialFeatures(degree=d, include_bias=include_bias)\n",
    "    # Instantiate a scaler.\n",
    "    std_scaler = StandardScaler()\n",
    "    # Instantiate a linear regressor.\n",
    "    lin_reg = LinearRegression()\n",
    "\n",
    "    # Create a pipeline of actions.\n",
    "    polynomial_regression = Pipeline([\n",
    "        (\"poly_features\", poly_features),\n",
    "        (\"std_scaler\", std_scaler),\n",
    "        (\"lin_reg\", lin_reg),\n",
    "    ])\n",
    "\n",
    "    lin_scores = cross_val_score(polynomial_regression, x_train, y_train, scoring='neg_mean_squared_error', cv=10)\n",
    "    scores = np.sqrt(-lin_scores)\n",
    "    mean_vec.append(scores.mean())\n",
    "    std_vec.append(scores.std())\n",
    "    \n",
    "    # Perform polynomial regression.\n",
    "    polynomial_regression.fit(x_train, y_train)\n",
    "    \n",
    "    y_train_predict = polynomial_regression.predict(x_train)\n",
    "    \n",
    "    y_val_predict = polynomial_regression.predict(x_val)    \n",
    "    \n",
    "    error_train.append(np.sqrt(mean_squared_error(y_train, y_train_predict)))\n",
    "\n",
    "    error_val.append(np.sqrt(mean_squared_error(y_val, y_val_predict)))\n",
    "\n",
    "# Plot results.\n",
    "plt.figure(figsize=(20, 5))\n",
    "ax = plt.subplot(1, 3, 1)\n",
    "plt.plot(range(1, 13), mean_vec,  label='Erro quadrático médio')\n",
    "plt.xticks(range(0, 13, 2))\n",
    "plt.xlim([1, 12])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "ax = plt.subplot(1, 3, 2)\n",
    "plt.plot(range(1, 13), std_vec,  label='Desvio padrão do erro')\n",
    "plt.xticks(range(0, 13, 2))\n",
    "plt.xlim([1, 12])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "ax = plt.subplot(1, 3, 3)\n",
    "plt.plot(range(1, 13), error_train, label='Erro de trainamento')\n",
    "plt.plot(range(1, 13), error_val, label='Erro de validação')\n",
    "plt.xticks(range(0, 13, 2))\n",
    "plt.xlim([1, 12])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "#Show the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [1, 3, 4, 10]\n",
    "\n",
    "plt.figure(figsize=(24, 5))\n",
    "for i in range(len(degrees)):\n",
    "    ax = plt.subplot(1, len(degrees), i + 1)\n",
    "\n",
    "    # Instantiate a polynomial.\n",
    "    poly_features = PolynomialFeatures(degree=degrees[i], include_bias=include_bias)\n",
    "    # Instantiate a scaler.\n",
    "    std_scaler = StandardScaler()\n",
    "    # Instantiate a linear regressor.\n",
    "    lin_reg = LinearRegression()\n",
    "\n",
    "    # Create a pipeline of actions.\n",
    "    polynomial_regression = Pipeline([\n",
    "        (\"poly_features\", poly_features),\n",
    "        (\"std_scaler\", std_scaler),\n",
    "        (\"lin_reg\", lin_reg),\n",
    "    ])\n",
    "\n",
    "    error_training = []\n",
    "    error_validation = []\n",
    "    error_test = []\n",
    "    for m in range(1,len(x_train)+1):\n",
    "\n",
    "        # Perform polynomial regression.\n",
    "        polynomial_regression.fit(x_train[:m], y_train[:m])\n",
    "\n",
    "        # Use the trained model for prediction of the training set.\n",
    "        y_train_predict = polynomial_regression.predict(x_train[:m])\n",
    "\n",
    "        # Use the trained model for prediction of the validation set.\n",
    "        y_val_predict = polynomial_regression.predict(x_val)       \n",
    "\n",
    "        # Calculate MSE for training set.\n",
    "        error_training.append(mean_squared_error(y_train[:m], y_train_predict))\n",
    "\n",
    "        # Calculate MSE for validation set.\n",
    "        error_validation.append(mean_squared_error(y_val, y_val_predict))     \n",
    "\n",
    "    plt.plot(range(1,len(x_train)+1), np.sqrt(error_training), label='Conjunto de treinamento')\n",
    "    plt.plot(range(1,len(x_train)+1), np.sqrt(error_validation), label='Conjunto de validação')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Tamanho do conjunto de treinamento', fontsize=14)\n",
    "    plt.ylabel('Raiz Quadrada do Erro Quadrático Médio', fontsize=14)\n",
    "    plt.grid()\n",
    "    #plt.ylim([1e-2, 10])\n",
    "    plt.title('Polinômio de ordem '+str(degrees[i]))\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "#Show the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 3\n",
    "include_bias = False\n",
    "\n",
    "# Instantiate a polynomial with the given degree.\n",
    "poly_features = PolynomialFeatures(degree=degree, include_bias=include_bias)\n",
    "# Instantiate a scaler that will standardize the features.\n",
    "std_scaler = StandardScaler()\n",
    "# Instantiate a linear regressor.\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Create a pipeline of actions.\n",
    "model = Pipeline([\n",
    "    (\"poly_features\", poly_features),\n",
    "    (\"std_scaler\", std_scaler),\n",
    "    (\"lin_reg\", lin_reg),\n",
    "])\n",
    "\n",
    "# Train model.\n",
    "model.fit(X, y)\n",
    "\n",
    "# Perform prediction for 100 days.\n",
    "X_pred = np.arange(1, 70).reshape(-1, 1)\n",
    "y_pred = model.predict(X_pred)\n",
    "X_pred = X_pred.reshape(1, -1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The growth curve in the model and other countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "    layout=go.Layout(\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        plot_bgcolor='rgba(0,0,0,0)'\n",
    "    )\n",
    ")\n",
    "\n",
    "for country, df_country in df_filtered.groupby(by='country'):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_country['days_from_k_case'],\n",
    "            y=df_country['active'],\n",
    "            mode='lines',\n",
    "            name=country+' - dia do início: '+str(initial_day.date())\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=X_pred,\n",
    "        y=y_pred,\n",
    "        mode='markers',\n",
    "        name='Prediction'\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=X_pred,\n",
    "        y=40600*np.ones(len(X_pred)),\n",
    "        mode='lines',\n",
    "        name='Número total de leitos de UTIs (adulto+pediátrico)'\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=X_pred,\n",
    "        y=17900*np.ones(len(X_pred)),\n",
    "        mode='lines',\n",
    "        name='Número total de leitos de UTIs (SUS)'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When will Brazil reach the limit of the public health system (SUS)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_do_colapso_leitos_uti_total = min([i+1 for i,v in enumerate(y_pred) if v >= 40600])\n",
    "dia1=df_filtered[(df_filtered['country']=='Brazil')]['date'].min() + timedelta(days=dia_do_colapso_leitos_uti_total)\n",
    "\n",
    "dia_do_colapso_leitos_uti_sus = min([i+1 for i,v in enumerate(y_pred) if v >= 17900])\n",
    "dia2=df_filtered[(df_filtered['country']=='Brazil')]['date'].min() + timedelta(days=dia_do_colapso_leitos_uti_sus)\n",
    "\n",
    "print('dia_do_colapso_leitos_uti_total: ', dia1.date())\n",
    "print('dia_do_colapso_leitos_uti_sus: ', dia2.date())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Currently, how far Brazil and Italy are from the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_brazil = df_filtered[(df_filtered['country']=='Brazil')]['active']\n",
    "brazil_model_diff = y_brazil ** (1/y_pred[0:len(y_brazil)])\n",
    "brazil_model_mean_diff = np.mean(brazil_model_diff)\n",
    "print('The difference between the model and the real data is %.2f %% in Brazil'%((brazil_model_mean_diff-1)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The growth curve in Brazil and Italy, and our distance for the max capacity in UTI (*Unidade de Tratamento Intensivo*, Intensive Care Unit) the Brazilian health system\n",
    "\n",
    "**Note:** Values for \"Max capacity of UTI in public health system (SUS)\" and \"Max capacity of UTI in public health system (SUS) + private sector\" are based on Brazilian health system (SUS). Source: Estadão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "    layout=go.Layout(\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        plot_bgcolor='rgba(0,0,0,0)'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=X_pred,\n",
    "        y=y_pred*brazil_model_mean_diff,\n",
    "        mode='markers',\n",
    "        name='Brazil Prediction (active cases)',\n",
    "        marker={\n",
    "            'color':'black',\n",
    "            'size': 2\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=X_pred,\n",
    "        y=y_pred*0.1*brazil_model_mean_diff,\n",
    "        mode='markers',\n",
    "        name='Brazil Prediction (active cases with UTI need)',\n",
    "        marker={\n",
    "            'color':'orange',\n",
    "            'size': 4\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_filtered[df_filtered['country']=='Italy']['days_from_k_case'],\n",
    "        y=df_filtered[df_filtered['country']=='Italy']['active'],\n",
    "        mode='lines',\n",
    "        name='Italy',\n",
    "        line={\n",
    "            'color':'red',\n",
    "            'width':5\n",
    "            \n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_filtered[df_filtered['country']=='Brazil']['days_from_k_case'],\n",
    "        y=df_filtered[df_filtered['country']=='Brazil']['active'],\n",
    "        mode='lines',\n",
    "        name='Brazil',\n",
    "        line={\n",
    "            'color':'black',\n",
    "            'width':5\n",
    "            \n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        name=\"Max capacity of UTI in public health system (SUS)\",\n",
    "        x = [0, 100],\n",
    "        y = [27400, 27400],\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        name=\"Max capacity of UTI in public health system (SUS) + private sector\",\n",
    "        x = [0, 100],\n",
    "        y = [17900, 17900],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
