{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Por que a função de ativação logística foi um ingrediente chave no treinamento das primeiras redes MLPs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função de ativação logística foi um ingrediente-chave no treinamento das primeiras MLPs, porque sua derivada é sempre diferente de zero; portanto, o Gradiente Descendente sempre pode \"rolar ladeira abaixo\". Quando a função de ativação é uma função de degrau, o Gradiente Descendente não pode se mover, pois não há inclinação (gradiente igual a zero)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suponha que você tenha uma rede MLP composta por uma camada de entrada com 10 neurônios, seguida por uma camada oculta com 50 neurônios e, finalmente, uma camada de saída com 3 neurônios. Todos os neurônios usam a função de ativação ReLU. Senso assim, responda\n",
    "(a) Qual é a dimensão da matriz de entrada X?\n",
    "\n",
    "(b) Qual a dimensão do vetor de pesos, Wh, da camada oculta e de seu vetor de bias bh?\n",
    "\n",
    "(c) Qual é a dimensão do vetor de pesos, Wo, da camada de saída e de seu vetor de bias bo?\n",
    "\n",
    "(d) Qual é a dimensão da matriz de saída, Y, da rede?\n",
    "\n",
    "(e) Escreva a equação que calcula a matriz de saída da rede, Y, como uma função de X, Wh, bh, Wo e bo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) A dimensão da matriz de entrada X é m x 10, onde m representa o tamanho do batch de treinamento.\n",
    "\n",
    "(b) A dimensão do vetor de pesos Wh da camada oculta é 10 x 50 e a dimensão de seu vetor de bias, bh, é 50.\n",
    "\n",
    "(c) A dimensão do vetor de pesos da camada de saída Wo é 50 x 3 e a dimensão de seu vetor de bias, bo, é 3.\n",
    "\n",
    "(d) A dimensão da matriz de saída Y da rede é m x 3.\n",
    "\n",
    "(e) Y = (X Wh + bh)Wo + bo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantos neurônios você precisa na camada de saída de uma rede MLP se você deseja classificar emails em spam ou ham? Qual função de ativação você deve usar na camada de saída? Se você deseja classificar a base de dados MNIST (imagens de dígitos escritos à mão), quantos neurônios você precisa na camada de saída usando qual tipo de função de ativação?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para classificar emails em spam ou ham, seria necessário apenas um neurônio na camada de saída de uma rede neural - por exemplo, indicando a probabilidade de um email ser spam. Normalmente, se usuaria a função de ativação logística na camada de saída ao estimar uma probabilidade. Se você deseja classificar a base de dados MNIST, seriam necessários 10 neurônios na camada de saída e deve-se substituir a função logística pela função de ativação softmax, que pode lidar com várias classes, gerando uma probabilidade por classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liste todos os hiperparâmetros que você pode ajustar em uma rede MLP? Caso você perceba que a rede MLP está sobreajustando, como você pode modificar esses hiperparâmetros para tentar resolver o problema?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os hiperparâmetros que poderiam ser ajustados em uma rede MLP são: o número de camadas ocultas, o número de neurônios em cada camada oculta e a função de ativação usada em cada camada oculta e na camada de saída. Em geral, a função de ativação ReLU é uma boa opção para a ativação das camadas ocultas. Para a camada de saída, em geral, pode-se usar a função de ativação logística para classificação binária, a função de ativação softmax para classificação de várias classes ou nenhuma função de ativação para regressão. Se a rede MLP estiver sobreajustando, pode-se tentar reduzir o número de camadas ocultas e/ou reduzir o número de neurônios por camada oculta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
